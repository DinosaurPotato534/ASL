{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ca551f2-7f62-44d0-a8ac-efeb76b197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91936a48-decb-4079-98c3-51e44475535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_training = \"/Users/aaryangulia/Downloads/archive/asl_alphabet_train/asl_alphabet_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61dc1677-c765-4740-8781-23fcd3df0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "num_classes = len(os.listdir(data_dir_training)) - 1\n",
    "\n",
    "# Define the image size and batch size\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Use ImageDataGenerator for data loading and augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale pixel values to [0, 1]\n",
    "    validation_split=0.2,  # Split data into training and validation sets\n",
    "    rotation_range=20,  # Randomly rotate images by up to 20 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically by up to 20% of the height\n",
    "    shear_range=0.2,  # Shear intensity (shear angle in radians)\n",
    "    zoom_range=0.2,  # Randomly zoom images by up to 20%\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba5adbf7-279a-47fa-b3d3-d96832c35920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 69600 images belonging to 29 classes.\n",
      "Found 17400 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir_training,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # For multi-class classification\n",
    "    subset='training'  # Specify this as training data\n",
    ")\n",
    "\n",
    "# Create validation data generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir_training,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'  # Specify this as validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8dac4f7-8b59-44d6-adef-b78ec57254f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained MobileNetV2 model without the top classification layer\n",
    "base_model = tf.keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom classification layers for your specific task\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')  # num_classes is the number of classes in your dataset\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Now, you can train the model with your own dataset using model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67dce2a4-cac6-40a4-a72d-a0bcf76c5f1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcf5afeb-0848-4d2f-af0e-7a87a53ea00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model summary: \n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 29)                37149     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2295133 (8.76 MB)\n",
      "Trainable params: 37149 (145.11 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print model summary to verify\n",
    "print(\"\\n Model summary: \")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "856a105b-48d9-47e3-a34c-cbcdd55466f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess an image\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = image.load_img(image_path, target_size=target_size)  # Load the image\n",
    "    img_array = image.img_to_array(img)  # Convert image to numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Rescale pixel values to [0, 1] as done during training\n",
    "    return img_array\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = '/Users/aaryangulia/Downloads/archive-2/Train_Alphabet/D/0ad4fbba-93fc-4bee-8056-0af4f58837d3.rgb_0000.png'\n",
    "processed_image = load_and_preprocess_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "990d9352-3778-40c8-ad17-202d382801c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted class: I\n",
      "Confidence: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using the pre-trained model\n",
    "predictions = model.predict(processed_image)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class_idx = np.argmax(predictions[0])\n",
    "\n",
    "# Decode the class index to get the class label (assuming you have a list of class labels)\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "predicted_class_label = class_labels[predicted_class_idx]\n",
    "\n",
    "# Get the confidence score of the prediction\n",
    "confidence = predictions[0][predicted_class_idx]\n",
    "\n",
    "# Print the results\n",
    "print(f'Predicted class: {predicted_class_label}')\n",
    "print(f'Confidence: {confidence:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c524a1c7-569f-4073-b276-e23dae45db1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n",
      "WARNING:absl:`mobilenetv2_1.00_224_input` is not a valid tf.function parameter name. Sanitizing to `mobilenetv2_1_00_224_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epoch3_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epoch3_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the Keras model\n",
    "tf.keras.models.save_model(model, 'epoch3_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "058686c1-7712-4cee-8db3-b6e56d5e4b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7ef48-08d9-4c80-8278-dfd471c57657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
