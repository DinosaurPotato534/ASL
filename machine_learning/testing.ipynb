{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748fb3c3-e6b9-4897-ac41-b2158b206a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f79998-a3e9-4bce-bb49-7193d8c252bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2700 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir_testing = \"/Users/aaryangulia/Downloads/archive-2/Test_Alphabet\"\n",
    "# Define the image size and batch size\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Use ImageDataGenerator for data loading and augmentation\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,  # Rescale pixel values to [0, 1]\n",
    "    validation_split=0.2,  # Split data into training and validation sets\n",
    "    rotation_range=20,  # Randomly rotate images by up to 20 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2,  # Randomly shift images vertically by up to 20% of the height\n",
    "    shear_range=0.2,  # Shear intensity (shear angle in radians)\n",
    "    zoom_range=0.2,  # Randomly zoom images by up to 20%\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Strategy for filling in newly created pixels\n",
    ")\n",
    "\n",
    "testing_generator = datagen.flow_from_directory(\n",
    "    data_dir_testing,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # For multi-class classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a178b55-cda9-47f0-b114-f5da6b3e563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess an image\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = image.load_img(image_path, target_size=target_size)  # Load the image\n",
    "    img_array = image.img_to_array(img)  # Convert image to numpy array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Rescale pixel values to [0, 1] as done during training\n",
    "    return img_array\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = '/Users/aaryangulia/Downloads/archive-2/Train_Alphabet/S/0c1b4b06-610a-4374-a784-aac831e6ff71.rgb_0000.png'\n",
    "processed_image = load_and_preprocess_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f133cead-b4ae-4b4e-b32b-e696b2f81da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('epoch_custom_model.h5',custom_objects={'KerasLayer': hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d93037d-807a-4162-b727-944c1b9c5f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model summary: \n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_3 (KerasLayer)  (None, 1001)              3540265   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 29)                29058     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 29)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3569323 (13.62 MB)\n",
      "Trainable params: 29058 (113.51 KB)\n",
      "Non-trainable params: 3540265 (13.51 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Model summary: \")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d992754e-8783-4cdb-85aa-74e26cf4690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n",
      "Predicted class: S\n",
      "Confidence: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using the pre-trained model\n",
    "predictions = model.predict(processed_image)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class_idx = np.argmax(predictions[0])\n",
    "\n",
    "# Decode the class index to get the class label (assuming you have a list of class labels)\n",
    "class_labels = list(testing_generator.class_indices.keys())\n",
    "predicted_class_label = class_labels[predicted_class_idx]\n",
    "\n",
    "# Get the confidence score of the prediction\n",
    "confidence = predictions[0][predicted_class_idx]\n",
    "\n",
    "# Print the results\n",
    "print(f'Predicted class: {predicted_class_label}')\n",
    "print(f'Confidence: {confidence:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54189317-5276-4ac4-8599-cedc6650626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epoch2_custom_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: epoch2_custom_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, 'epoch2_custom_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302c5f6-b57b-4416-8e62-1baa776cf476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
