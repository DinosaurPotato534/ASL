{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce3f293-0a86-4da8-ab30-fb93e67b42aa",
   "metadata": {},
   "source": [
    "# This Notebook is for testing models that have been trained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b414e04f-a425-4b9c-ab64-5c09d182c681",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748fb3c3-e6b9-4897-ac41-b2158b206a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "#these need the necessary pip install instructions to run\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "85f79998-a3e9-4bce-bb49-7193d8c252bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1998 images belonging to 19 classes.\n"
     ]
    }
   ],
   "source": [
    "#take the directory that contains the testing data set\n",
    "data_dir_testing = \"/Users/aaryangulia/Downloads/spanish_sl\"\n",
    "\n",
    "# Define the image size and batch size for the testing data set \n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# Use ImageDataGenerator for data loading and augmentation\n",
    "#innovatively augmented the data to be able to make most out of the least epochs and efficiently pass in data points\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    validation_split=0.2,  \n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2,  \n",
    "    shear_range=0.2,  \n",
    "    zoom_range=0.2,  \n",
    "    horizontal_flip=True,  \n",
    "    fill_mode='nearest'  \n",
    ")\n",
    "#generate the testing data set\n",
    "testing_generator = datagen.flow_from_directory(\n",
    "    data_dir_testing,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a178b55-cda9-47f0-b114-f5da6b3e563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load and preprocess an image\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = image.load_img(image_path, target_size=target_size) \n",
    "    img_array = image.img_to_array(img)  \n",
    "    img_array = np.expand_dims(img_array, axis=0)  \n",
    "    img_array /= 255.0 \n",
    "    return img_array\n",
    "\n",
    "# Load and preprocess the image\n",
    "image_path = '/Users/aaryangulia/Downloads/indian_sl/5/46.jpg'\n",
    "processed_image = load_and_preprocess_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f133cead-b4ae-4b4e-b32b-e696b2f81da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('epoch_custom_model.h5',custom_objects={'KerasLayer': hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5d93037d-807a-4162-b727-944c1b9c5f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model summary: \n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_4 (KerasLayer)  (None, 1001)              3540265   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 36)                36072     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 36)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3576337 (13.64 MB)\n",
      "Trainable params: 36072 (140.91 KB)\n",
      "Non-trainable params: 3540265 (13.51 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Model summary: \")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d992754e-8783-4cdb-85aa-74e26cf4690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 491ms/step\n",
      "Predicted class: E\n",
      "Confidence: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using the pre-trained model\n",
    "predictions = model.predict(processed_image)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class_idx = np.argmax(predictions[0])\n",
    "\n",
    "# Decode the class index to get the class label (assuming you have a list of class labels)\n",
    "class_labels = list(testing_generator.class_indices.keys())\n",
    "predicted_class_label = class_labels[predicted_class_idx]\n",
    "\n",
    "# Get the confidence score of the prediction\n",
    "confidence = predictions[0][predicted_class_idx]\n",
    "\n",
    "# Print the results\n",
    "print(f'Predicted class: {predicted_class_label}')\n",
    "print(f'Confidence: {confidence:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4302c5f6-b57b-4416-8e62-1baa776cf476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-107-98e7fa83ce57>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  evaluation = model.evaluate_generator(testing_generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.2418\n",
      "Test Accuracy: 28.33%\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate_generator(testing_generator)\n",
    "print(f'Test Loss: {evaluation[0]:.4f}')\n",
    "print(f'Test Accuracy: {evaluation[1]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e37efc8-c845-49ff-b6de-20131a8d4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_layer_weights = model.layers[-1].get_weights()\n",
    "second_last_layer_weights = model.layers[-2].get_weights()\n",
    "\n",
    "# Modify the weights as desired and then go back and test the model. re-iterate through the process to get optimal weights for custom layers\n",
    "final_layer_weights = [weight * 1.5 for weight in final_layer_weights]\n",
    "modified_second_last_layer_weights = [weight * 1.2 for weight in second_last_layer_weights]\n",
    "\n",
    "# Set the modified weights back to the layers\n",
    "model.layers[-1].set_weights(final_layer_weights)\n",
    "model.layers[-2].set_weights(modified_second_last_layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baff76a-08c2-433d-9bad-1af08eb32515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "54189317-5276-4ac4-8599-cedc6650626a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: arabic_sl_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: arabic_sl_model/assets\n"
     ]
    }
   ],
   "source": [
    "#save the data set if it works well. this format is the best to convert to TensorFlowJs!\n",
    "tf.keras.models.save_model(model, 'arabic_sl_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d3649-10db-4cf1-9af6-d7f2c094f538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
