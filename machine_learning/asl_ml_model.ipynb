{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01fc78b9-a93f-4e3e-aee3-59f6e80c03b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7be9e2f-b3a6-4f5e-afa5-4f8e387bafac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87000 files belonging to 29 classes.\n",
      "Using 69600 files for training.\n"
     ]
    }
   ],
   "source": [
    "data_dir_training = \"archive/asl_alphabet_train/asl_alphabet_train\"\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_training,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=253,\n",
    "  batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92aa3c57-ddef-4dc4-b080-ce1039aebca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 87000 files belonging to 29 classes.\n",
      "Using 17400 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_training,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=253,\n",
    "  batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2708f665-1df3-49a1-a0d3-b727cc42d64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d9fee15-9788-4ac0-8fe1-d621ea180c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_SkipDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.skip(60000)\n",
    "val_ds.skip(16500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cd72f63-bf7d-4f59-8269-9391f8998ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23459de8-1667-41b6-aab0-1b58c5329b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3596afe0-65e4-4a09-ba09-e017c3713b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dense(5, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08378b4c-d0a2-4119-90d8-675ed3b891fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc328393-d4b6-4593-8618-8ce14e386e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/opt/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 1046, in launch_instance\n      app.start()\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n      result = self._run_cell(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n      return runner(coro)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-37-471bb77471a2>\", line 2, in <module>\n      history = model.fit(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [262144,29] and labels shape [16]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1684]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-471bb77471a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/opt/anaconda3/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/anaconda3/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/opt/anaconda3/lib/python3.8/site-packages/traitlets/config/application.py\", line 1046, in launch_instance\n      app.start()\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/opt/anaconda3/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/opt/anaconda3/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2877, in run_cell\n      result = self._run_cell(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n      return runner(coro)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3146, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-37-471bb77471a2>\", line 2, in <module>\n      history = model.fit(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n      return self.compiled_loss(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/losses.py\", line 2354, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/src/backend.py\", line 5762, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [262144,29] and labels shape [16]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1684]"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a7edd863-7d02-443c-a473-12bdad0cbed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d93150-b7ac-47ba-a18d-6b24f1b023d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_train_data = ImageDataGenerator(horizontal_flip=True,\n",
    "                                        rotation_range=50,\n",
    "                                        zoom_range=0.2,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.2,\n",
    "                                        rescale=1./255)\n",
    "\n",
    "train_dataset = augment_train_data.flow_from_directory(data_dir_training,\n",
    "     shuffle=True,\n",
    "     classes=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "     'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'space', 'del', 'nothing'],\n",
    "     target_size=(224, 224),\n",
    "     batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "017f06c1-a185-493f-ac57-bdd0219ee8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model summary: \n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_5 (KerasLayer)  (None, 1001)              3540265   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 29)                29058     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 29)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3569323 (13.62 MB)\n",
      "Trainable params: 29058 (113.51 KB)\n",
      "Non-trainable params: 3540265 (13.51 MB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " Model Training: \n",
      "2719/2719 [==============================] - 1874s 688ms/step - loss: 0.8185 - accuracy: 0.7518\n",
      "\n",
      " Model Evaluation: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-afdde2012431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# evaluating model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n Model Evaluation: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# getting pretrained model for transfer learning and defining model\n",
    "url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "download_model = hub.KerasLayer(url,input_shape=(224,224,3))\n",
    "model = Sequential([\n",
    "     download_model,\n",
    "     Dense(29),\n",
    "     Activation(\"softmax\")\n",
    "])\n",
    "# compiling model\n",
    "model.compile(optimizer=Adam(1e-3),\n",
    "loss=\"categorical_crossentropy\",\n",
    "metrics=['accuracy'])\n",
    "#training model\n",
    "print(\"\\n Model summary: \")\n",
    "print(model.summary())\n",
    "print(\"\\n Model Training: \")\n",
    "model.fit(train_dataset,\n",
    "batch_size=16,\n",
    "epochs=1)\n",
    "# evaluating model\n",
    "print(\"\\n Model Evaluation: \")\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2eda41-febf-417b-8b16-c7a19856db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d592788b-148d-48b6-8f09-289a1ed7e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#load the model we saved\n",
    "test_image = image.load_img('/Users/aaryangulia/Downloads/archive-2/Test_Alphabet/A/1e5fcac0-0494-4fcb-9dcc-a7c17403abe9.rgb_0000.png', target_size=(224, 224,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5c58901c-acfa-4605-9a06-aea62121cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = tf.keras.utils.img_to_array(test_image)/255.0\n",
    "img_array = tf.expand_dims(img_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4e1846f5-4e58-4a90-aecf-bf019e941ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "This image most likely belongs to A with a 8.82 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7fd3918-a6bf-4eb6-b948-04df5ef1fc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "INFO:tensorflow:Assets written to: models/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Load the existing model\n",
    "model = tf.keras.models.load_model(\"models/english_model.h5\", custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "\n",
    "# Register the KerasLayer\n",
    "tf.keras.utils.get_custom_objects()['KerasLayer'] = hub.KerasLayer\n",
    "\n",
    "# Save the model to the TensorFlow.js format\n",
    "tf.saved_model.save(model, \"models/saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba880f-cdee-4097-9a8b-ad5bbcd33631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
